# Interpretable AI

A repository for all things interpretability. The code in this repo was written to support my [blog post](https://towardsdatascience.com/interpretable-ai-or-how-i-learned-to-stop-worrying-and-trust-ai-e61f9e8ee2c2) on this topic.

## Additional Resources

### Examples of AI Propagating Bias

- Criminal Justice 
  - COMPAS
    - [Machine Bias: Risk Assessments in Criminal Sentencing](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing)
    - [How we analyzed the COMPAS recidivism algorithm](https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm)
  - DragNet Surveillance
    - [Policing Digital Traces: Talk by Sarah Brayne at AI Now 2017](https://www.youtube.com/watch?v=AnZ-YpIagXs&index=13&list=PLsHf1QGJz7uvFMIYj6oxwKXfIRzNpyzPe)
    - [I'm an Amazon employee. My company shouldn't sell facial recognition tech to police.](https://medium.com/s/powertrip/im-an-amazon-employee-my-company-shouldn-t-sell-facial-recognition-tech-to-police-36b5fde934ac)
- Retail
  - [Amazon Same Day Delivery](https://www.bloomberg.com/graphics/2016-amazon-same-day/?cmpid=google)
- Computer Vision
  - [The Algorithmic Justice League](https://medium.com/mit-media-lab/the-algorithmic-justice-league-3cc4131c5148)
  - [How I'm fighting bias in Algorithms: TED Talk by Joy Buolamwini](https://www.ted.com/talks/joy_buolamwini_how_i_m_fighting_bias_in_algorithms)
- Language
  - [Man is to Computer Programmer as Woman is to Homemaker?](https://arxiv.org/pdf/1607.06520.pdf)
  - [Microsoft Tay.ai Chat Bot](https://www.theverge.com/2016/3/24/11297050/tay-microsoft-chatbot-racist)
- [Trouble with Bias: Talk by Kate Crawford at NeurIPS 2017](https://www.youtube.com/watch?v=fMym_BKWQzk)
- [Bias Traps in AI: Panel Discussion at AI Now 2017](https://www.youtube.com/watch?v=JiWRnkMyAsc)

### Research Papers

- [The Mythos of Model Interpretability (2017)](https://arxiv.org/pdf/1606.03490.pdf)
- [Survey of Methods for Explaining Black Box Models (2018)](https://arxiv.org/pdf/1802.01933.pdf)
- [Challenges for Transparency (2017)](https://arxiv.org/pdf/1708.01870.pdf)
- [Manipulating and Measuring Model Interpretability (2018)](https://arxiv.org/pdf/1802.07810.pdf)
- [Datasheets for Datasets (2018)](https://arxiv.org/pdf/1803.09010.pdf)
- [A Causal Framework for Explaining Predictions of Black Box Sequence-to-Sequence Models](https://arxiv.org/pdf/1707.01943.pdf)
- [European Union Regulations on Algorithmic Decision-Making and a "Right to Explanation"](https://arxiv.org/pdf/1606.08813.pdf)
- [Consistent feature attribution for tree ensembles (2018)](https://arxiv.org/pdf/1706.06060.pdf)
- [A Unified Approach to Interpreting Model Predictions (2017)](http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions)
- [Towards a Rigorous Science of Interpretable ML (2017)](https://arxiv.org/pdf/1702.08608.pdf)
- [Why should I trust you? Explaining the predictions of any classifier (2016)](https://arxiv.org/pdf/1602.04938.pdf)
- [Anchors: High Precision Model-Agnostic Explanations (2018)](https://homes.cs.washington.edu/~marcotcr/aaai18.pdf)
- [DeepLIFT: Learning Important Features through Propagating Activation Differences](https://arxiv.org/pdf/1704.02685.pdf)
- [Explaining Explanations: An Approach to Evaluating Interpretability of Machine Learning (2018)](https://arxiv.org/pdf/1806.00069.pdf)
- [Interpretable Machine Learning for Privacy-Preserving Pervasive Systems (2017)](https://arxiv.org/ftp/arxiv/papers/1710/1710.08464.pdf)
- [How do humans understand explanations from ML Systems? An Evaluation of the Human-Interpretability of Explanation (2018)](https://arxiv.org/pdf/1802.00682.pdf)
- [Opportunities in ML for Healthcare (2018)](https://arxiv.org/pdf/1806.00388.pdf)
- [Predictive Learning via Rule Ensembles (RuleFit) (2005)](http://statweb.stanford.edu/~jhf/ftp/RuleFit.pdf)
- [Ethics and AI](http://cgis.cs.umd.edu/class/fall2012/cmsc828d/oldreportfiles/schulze1.pdf)
- [Building Ethics into AI (2018)](https://www.ijcai.org/proceedings/2018/0779.pdf)
- [Deep kNN: Towards Confident, Interpretable and Robust Deep Learning (2018)](https://arxiv.org/pdf/1803.04765.pdf)

### Blogs

- [The Inescapability of Uncertainty](https://points.datasociety.net/uncertainty-edd5caf8981b)
- [Demystifying black box models](https://medium.com/civis-analytics/demystifying-black-box-models-with-shap-value-analysis-3e20b536fc80)
- [Ideas on Interpreting Machine Learning](https://www.oreilly.com/ideas/ideas-on-interpreting-machine-learning)
- [What's new in DL Research: Reducing Bias and Discrimination in ML Models with AI Fairness 360](https://towardsdatascience.com/whats-new-in-deep-learning-research-reducing-bias-and-discrimination-in-machine-learning-models-be116d3a571c)
- [Visualising high dimensional data using PCA and t-SNE](https://medium.com/@luckylwk/visualising-high-dimensional-datasets-using-pca-and-t-sne-in-python-8ef87e7915b)
- [Use t-SNE to visualise how your model thinks](https://buzzrobot.com/using-t-sne-to-visualise-how-your-deep-model-thinks-4ba6da0c63a0)

### Books

- [Interpretable Machine Learning by Christoph Molnar (2018)](https://christophm.github.io/interpretable-ml-book/limo.html)

### Videos

- [Bias Traps in AI | AI Now 2017](https://www.youtube.com/watch?v=JiWRnkMyAsc)
- [Policing Digital Traces | Sarah Brayne](https://www.youtube.com/watch?v=AnZ-YpIagXs&index=13&list=PLsHf1QGJz7uvFMIYj6oxwKXfIRzNpyzPe)
- [How I'm fighting bias in algorithms | Joy Buolamwini](https://www.ted.com/talks/joy_buolamwini_how_i_m_fighting_bias_in_algorithms)
- [The Trouble with Bias | Kate Crawford](https://www.youtube.com/watch?v=fMym_BKWQzk)
- [Programming your way to Explainable AI | Mark Hammond](https://www.youtube.com/watch?v=fMym_BKWQzk)